---
title: 'Wildfire Smoke and Mortality '
author: "Ryan Gan"
output:
  html_document:
    df_print: paged
  html_notebook:
    number_sections: yes
editor_options:
  chunk_output_type: inline
---

# Introduction

This notebook contains code and methods to evaluate the association between wildfire smoke and inpatient via emergency room morbidity. I will be using daily county-level counts of cardiopulmonary emergency room visits that resulted in a hospital inpatient admission as my primary outcome.

## Set up

Setting up knitr chunk options.

```{r kniter_opt}
knitr::opts_chunk$set(fig.height = 6, fig.width = 8, fig.align = "center",
                      progress = F)
```

Loading the tidyverse package, which contains most packages I will need for data cleaning, visualizations, and analysis. Loading stringr package for character string manipulation.

```{r packages}
library(tidyverse) # all-purpose packages
library(stringr) # working with character strings
library(sf) # spatial package
library(lme4) # loading lme4 mixed model package
library(splines) # splines package
```

Setting up dark plot color theme.

```{r ggtheme}
ryan_theme <- theme(panel.background = element_rect(fill = "black", 
          colour = "black", size = 0.5, linetype = "solid"),
        panel.grid.major = element_line(size = 0.2, colour = "white"),
        panel.grid.minor = element_line(size = 0.1, color = "white", 
                                        linetype = "dotted"),
        plot.background = element_rect(fill = "#141e30", colour="#141e30",
                                       size = 0.5, linetype = "solid"),
        text = element_text(colour = "white"),
        axis.text = element_text(colour = "white"),
        strip.background = element_blank(),
        strip.text = element_text(colour="white"),
        legend.background = element_blank(),
        legend.key = element_blank())
```

## Data Import

Importing the Colorado and Washington state inpatient emergency department visits.

#### Note 2018-01-29: 
Consider adding all inpatient visits as well for all these states. Would this be a general question of hospital utilization?

Importing Colorado 2010 to 2015 time series and viewing first observations.

```{r colorado_import}
# define relative path to data folder
co_path <- paste0("../../data/health/2010-2015_morbidity_co_ts.csv")
# read in dataframe using read_csv function from tidyverse package
co_ts <- read_csv(co_path, progress = F) 
# glimpse first observations
glimpse(co_ts)
```

Importing Washington 2011 to 2015 time series and viewing first observations.

```{r washington_import}
# define relative path
wa_path <- paste0("../../data/health/2011-2015_morbidity_wa_ts.csv")
# read in dataframe
wa_ts <- read_csv(wa_path, progress = F) %>% 
  mutate(fips = as.character(fips))
# glimpse first obs
glimpse(wa_ts)
```

Spot for Oregon import.

## Census Population 

Importing Census denominator data. Using total population for now, but I may have Jingyang estimate sex and age strata denominators for these counties/years.

```{r read_denom}
# colorado census
co_denom <- read_csv("../../data/census/2016-colorado_population.csv") %>% 
  select(GEO.id2, 'GEO.display-label', respop72010:respop72016) %>% 
  rename(fips = GEO.id2, county = 'GEO.display-label') %>% 
  rename_at(vars(respop72010:respop72016), 
            funs(paste0("pop",str_sub(., start=8)))) %>% 
  # take out state name and "county" from county name
  mutate(county = str_split_fixed(county, " County", n=2)[,1])
# sum up counties to get a state total
co_denom_total <- co_denom %>% 
  summarise_at(vars(pop2010:pop2016), sum) %>% 
  gather(key="year", value = "pop", pop2010:pop2016) %>% 
  mutate(year = as.numeric(str_sub(year, start = 4)))

# washington cesus
wa_denom <- read_csv("../../data/census/2016-washington_population.csv") %>% 
  select(GEO.id2, 'GEO.display-label', respop72010:respop72016) %>% 
  rename(fips = GEO.id2, county = 'GEO.display-label') %>% 
  rename_at(vars(respop72010:respop72016), 
            funs(paste0("pop",str_sub(., start=8)))) %>% 
  # take out state name and "county" from county name
  mutate(county = str_split_fixed(county, " County", n=2)[,1])
# sum up counties to get a state total
wa_denom_total <- wa_denom %>% 
  summarise_at(vars(pop2010:pop2016), sum) %>% 
  gather(key="year", value = "pop", pop2010:pop2016) %>% 
  mutate(year = as.numeric(str_sub(year, start = 4)))
```

Viewing Colorado and Washington population totals over time.

```{r pop_plot}
# bind population denoms together
pop_totals <- bind_rows(mutate(co_denom_total, state = "colorado"),
                        mutate(wa_denom_total, state = "washington"))

# plot
ggplot(data = pop_totals, aes(x=year, y=pop, color = state)) +
  geom_point() +
  ylim(4000000, 8000000) +
  ylab("Popuulation") +
  xlab("Year") +
  ggtitle("State population by year") +
  ryan_theme
```

Washington has about 2 million more people residing in the state compared to Colorado. Both states have a similar rate of population growth over the 7 year period. We could possibly account for this rate in the denominator.

I'm going to prepare the 2015 Washington and Colorado county denominators that will be joined to the analysis data frame later on.
```{r county_denom_2015}
county_denom <- wa_denom %>% 
  mutate(fips = as.character(fips)) %>% 
  bind_rows(co_denom) %>% 
  # add state variable in
  mutate(state = if_else(str_sub(fips, 1, 2)=="08",
                        "Colorado", "Washington")) %>% 
  select(fips, state, county, pop2015) %>% 
  rename(population = pop2015)
```

# Inpatient emergency room time series

I'm limiting to only total admissions strata and taking the sum across all counties for state sums and gathering specific outcome counts from columns to rows so that I can plot small multiples. I've then joined in the state yearly rate by the year in which I have counts for. 
```{r state_aggregate}
# aggregate colorado
co_aggregate <- co_ts %>% 
  filter(strata =="total") %>% 
  group_by(date) %>%
  summarise_at(vars(resp:cardiopulm_n), sum) %>% 
  gather(key ="outcome", value = "n", resp:cardiopulm_n) %>% 
  mutate(year = lubridate::year(date)) %>% 
  left_join(co_denom_total, by = "year") %>% 
  mutate(rate1mil = (n/pop)*1000000)

# aggregate washington
wa_aggregate <- wa_ts %>% 
  filter(strata == "total") %>% 
  group_by(date) %>% 
  summarise_at(vars(resp:cardiopulm_n), sum) %>% 
  gather(key ="outcome", value = "n", resp:cardiopulm_n) %>% 
  mutate(year = lubridate::year(date)) %>% 
  left_join(wa_denom_total, by = "year") %>% 
  mutate(rate1mil = (n/pop)*1000000)
```

I'm going to plot the state time series of rates by outcome, but I am first going to divide up by respiratory outcomes and then cardiovascular outcomes and compare state to state.

## Respiratory 

Subsetting respiratory outcomes for both Colorado and Washington and combining in to one data frame.

```{r resp_dataframe}
# colorado respiratory
co_resp <- co_aggregate %>% 
  filter(outcome %in% c("resp", "asthma", "copd", 
                        "acute_bronch", "pneum")) %>% 
  mutate(state = "colorado")
# washington respiratory
wa_resp <- wa_aggregate %>% 
  filter(outcome %in% c("resp", "asthma", "copd", 
                        "acute_bronch", "pneum")) %>% 
  mutate(state = "washington")

# bind datasets together and set order of factors
resp_ts <- bind_rows(co_resp, wa_resp) %>% 
  mutate(outcome_group = as.factor(paste(str_sub(state, 1, 2), 
                                         outcome, sep = "_")),
    outcome_group = forcats::fct_relevel(outcome_group, 
    "co_resp", "co_asthma", "co_copd",
    "co_acute_bronch", "co_pneum", 
    "wa_resp", "wa_asthma", "wa_copd",
    "wa_acute_bronch", "wa_pneum"))
```

Plot of state respiratory outcomes.

```{r state_resp_plot} 
ggplot(resp_ts, aes(x=date,y=rate1mil)) +
  geom_point(color = "#00dbde", size = 0.1) +
  facet_wrap(~outcome_group, nrow = 2) +
  scale_x_date(date_labels = "'%y") +
  ylab("Rate per 1 million") +
  xlab("Date") +
  ggtitle("Respiratory outcome rate from 2010 to 2016") +
  ryan_theme
```

The overall respiratory emergency room hospitalization rate per million persons looks similar between Colorado and Washington (note Washington does not have 2010 data). Colorado's overall respiratory rate may fluctuate slightly more though. For both states, around New Years, I see noticeable drops in the rate, which may suggestion needing to account for this in models.

### 2015 Respiratory Trends

Limiting time series plot to 2015-06-01 to 2015-09-30 to look at cardiovascular trends during the same period for which I have PM~2.5~ data from.

As of right now, I only have smoke exposure estimates from the summer of 2015. I'm going to limit the outcome time series to only 2015 to evaluate trends. Also, note that both states did not provide 2015 data after October 2015. This is when ICD-9 switched to ICD-10; those are separate data sets. I was fine not receiving these data sets for the time being.

I'm also allowing the y-axis scales to vary to see if there is variability over time for the sub outcomes.

```{r resp_plot_2015}
resp15 <- resp_ts %>% 
  filter(date >= "2015-06-01" & date <= "2015-09-30")
# plot
ggplot(resp15, aes(x=date,y=rate1mil)) +
  geom_point(color = "#00dbde", size = 0.5) +
  facet_wrap(~outcome_group, nrow = 2, scales = "free_y") +
  ylab("Rate per 1 million") +
  xlab("2015") +
  ggtitle("Respiratory outcome rate 2015") +
  ryan_theme
```

Come back and add some horizontal lines to indicate major smoke events. May be something with Asthma for both states, but that's also the period when the rates start to increase.

## Cardiovascular

Subsetting cardiovascular outcomes for both Colorado and Washington and combining in to one data frame.

```{r cvd_dataframe}
# colorado respiratory
co_cvd <- co_aggregate %>% 
  filter(outcome %in% c("cvd", "arrhythmia", "ihd", 
                        "mi", "hf", "cereb_vas")) %>% 
  mutate(state = "colorado")
# washington respiratory
wa_cvd <- wa_aggregate %>% 
  filter(outcome %in% c("cvd", "arrhythmia", "ihd", 
                        "mi", "hf", "cereb_vas")) %>% 
  mutate(state = "washington")

# bind datasets together and set order of factors
cvd_ts <- bind_rows(co_cvd, wa_cvd) %>% 
  mutate(outcome_group = as.factor(paste(str_sub(state, 1, 2), 
                                         outcome, sep = "_")),
    outcome_group = forcats::fct_relevel(outcome_group, 
    "co_cvd", "co_arrhythmia", "co_ihd", "co_mi", "co_hf", "co_cereb_vas", 
    "wa_cvd", "wa_arrhythmia", "wa_ihd", "wa_mi", "wa_hf", "wa_cereb_vas"))
```

Plot of CVD rate for Colorado and Washington.

```{r state_cvd_plot} 
ggplot(cvd_ts, aes(x=date,y=rate1mil)) +
  geom_point(color = "#e100ff", size = 0.1) +
  facet_wrap(~outcome_group, nrow = 2) +
  scale_x_date(date_labels = "'%y") +
  ylab("Rate per 1 million") +
  xlab("Date") +
  ggtitle("CVD outcome rate from 2010 to 2016") +
  ryan_theme
```

Overall, the rate for cardiovascular outcomes does not exhibit the same seasonal trends as respiratory outcomes, and remains relatively stable over the period. The rate looks almost 50% higher for Washington; I'm not sure if this might be a true trend or if it's more of an artifact of differences in the discharge data sets provided by the states.

### 2015 Cardiovascular Trends

Limiting time series plot to 2015-06-01 to 2015-09-30 to look at cardiovascular trends during the same period for which I have PM~2.5~ data from.

```{r cvd_plot_2015}
cvd15 <- cvd_ts %>% 
  filter(date >= "2015-06-01" & date <= "2015-09-30")
# plot
ggplot(cvd15, aes(x=date,y=rate1mil)) +
  geom_point(color = "#e100ff", size = 0.5) +
  facet_wrap(~outcome_group, nrow = 2, scales = "free_y") +
  ylab("Rate per 1 million") +
  xlab("2015") +
  ggtitle("Cardiovascular outcome rate 2015") +
  ryan_theme
```

One trend that kind of sticks out is that the rate of heart failure admissions in Washington is noticeably higher compared to Colorado, and there might be a slight decrease in the rate over time. Also, I've noticed that near the end of time series (October), there is systematic dip in all time series. This could be a reporting/quality assurance issue, or perhaps some hospitals had begun to transition to ICD-10 coding. In any case, it may be worth chopping off the last couple dates in September.

# PM~2.5~

Reading in PM~2.5~ data estimated using kriging and geographically-weighted ridge regression (GWR).

```{r pm_import}
# read pm data and subset to colorado
pm_path <- paste0("../../data/smoke/2015-smoke_wus_county_popwt.csv")
# read pm
pm <- read_csv(pm_path) %>% 
  mutate(smoke0 = ifelse(gwr_smk > 0, 1, 0),
         smoke5 = ifelse(gwr_smk > 5, 1, 0),
         smoke10 = ifelse(gwr_smk > 10, 1, 0),
         smoke15 = ifelse(gwr_smk > 15, 1, 0))

glimpse(pm)
```

Note, I didn't create a smoke-wave binary variable because the 98^th^ percentile with this reduced time series is skewed (36 ug/m^3^).

## Smoke Map

First thing I am going to do is look at the spatial resolution of smoke using counts of number of smoke days by county with a map. I will use the "sf" package, which works with tidyverse. However, "sf" requires the latest version of R and also requires the development version of ggplot.

Counting up smoke days using the > 10 ug/m^3^ cutoff for GWR smoke in each county.

```{r smoke_count}
# count up smoke events for each county
smoke_count <- pm %>% 
  group_by(fips) %>% 
  summarise(smoke0 = sum(smoke0), smoke5 = sum(smoke5), 
            smoke10 = sum(smoke10), smoke15 = sum(smoke15))

# read in county shapefile and subset to only colorado fips
county_sf <- st_read("../../data/shapefile/us_county", 
                        layer = "us_county") %>% 
  # create fips variable
  mutate(fips = paste0(STATEFP, COUNTYFP)) %>% 
  # filter to counties in western US states
  filter(fips %in% unique(pm$fips)) %>% 
  # join with smoke counts
  left_join(smoke_count, by = "fips")  

# extract projection
wgs84 <- st_crs(county_sf)

# read state lines sf file
state_sf <- st_read("../../data/shapefile/us_state", 
                    layer = "cb_2016_us_state_20m") %>% 
  filter(STATEFP %in% county_sf$STATEFP) %>% 
  # assign wgs84 projection
  st_transform(wgs84) 
```

Mapping number of smoke days where GWR PM~2.5~ > 10 ug/m^3^.

```{r smoke map}
ggplot(county_sf) +
  geom_sf(aes(fill = smoke10), color = "#53346d") +
  scale_fill_gradient("Smoke Days", low="white", high="#ff00cc") +
  geom_sf(data = state_sf, color = "#7303c0", alpha = 0) +
  ryan_theme
```

It looks like most of the smoke impacted the Eastern part of Washington, Idaho,
Montana, and parts of Southern Oregon and Northern California. Some impact in Wyoming and Colorado.

## PM~2.5~ Time series plots

I'm going to summarize time series of PM~2.5~ by state for now. I'll look for regional boundary maps to help divide up the states a bit. Educational regions is an option.

Could also use a plotly type map to allow for more interaction. I'll consider this if it would be useful.
Link to plotly example:
https://blog.cpsievert.me/2018/01/30/learning-improving-ggplotly-geom-sf/

Wrangling data in order to plot by state. First section of code is finding the median of the background estimates. Second part is preparing Colorado and Washington PM~2.5~ values for plotting.

```{r pm_aggregate}
# find the median pm of background for each state
state_background <- pm %>% 
  filter(str_sub(fips, 1,2) %in% c("08", "53")) %>% 
  mutate(state = if_else(str_sub(fips,1,2)=="08", "co", "wa")) %>% 
  group_by(state) %>% 
  summarise(median_pm = median(background_med))

# subset to only washington and colorado
pm_aggregate <- pm %>% 
  filter(str_sub(fips, 1,2) %in% c("08", "53")) %>% 
  mutate(state = if_else(str_sub(fips,1,2)=="08", "co", "wa")) %>% 
  select(-(smoke0:smoke15), -gwr_smk, -krig_smk, -background_med) %>% 
  gather(key = "method", value = "pm", gwr, krig) %>% 
  mutate(state_method = paste(state, method, sep = "_"))
```

Plotting time series of county values of PM~2.5~ for each state and method from 2015-06-01 to 2015-09-30. I've added in the background levels (red line).

```{r pm_plot}
state_background
ggplot(pm_aggregate, aes(x=date, y=pm, group=fips)) +
  geom_line(colour = "#93f9b9") +
  geom_hline(aes(yintercept = 4.43), 
             colour = "red")+
  facet_wrap(~state_method) +
  ylab("PM2.5 ug/m^3") +
  xlab("2015") +
  ggtitle("PM2.5 for each county by state and estimation method") +
  ryan_theme
```

Looks like there were a couple notable smoke events at the start of July and again in the middle of August in Colorado. I believe this smoke was transported from the Pacific Northwest fires as there weren't any large fires in Colorado during this time. Washington has notably higher PM~2.5~ values in late August; also has more period impacted by smoke (early July, early August, late August).

# Association between PM~2.5~ and Morbidity

Now that I've looked at the time series of the emergency room hospitalizations and PM~2.5~, I'll see if there is any association between two.

```{r morbidity_pm_df}
ed_ts <- co_ts %>% 
  # bind colorado and washington time series together
  bind_rows(wa_ts) %>% 
  # filter to dates I have PM2.5 estimates for
  filter(date >= "2015-06-01" & date <= "2015-09-30") %>% 
  mutate(year = lubridate::year(date)) %>% 
  # join with county denoms
  left_join(county_denom, by = "fips") %>% 
  # join with pm values
  left_join(pm, by = c("date", "fips")) %>% 
  # create weekend variable
  mutate(day = as.factor(weekdays(date)),
    weekend = ifelse(day %in% c("Saturday", "Sunday"), 1, 0),
    month = as.factor(lubridate::month(date)),
    # create pm 10 unit change v ariables
    gwr_smk10 = gwr_smk/10,
    krig_smk10 = krig_smk/10,
    gwr10 = gwr/10,
    krig10 = krig/10)
```

## Poisson Mixed Model

I'm limiting data analysis to the "total" strata for now. This is the group that makes no distinction about strata.

Running a Poisson random effects model. Regressing cardiopulmonary ED visits on GWR smoke by 10 ug/m^3^. Assuming a linear relationship. In addition to treating each county as a random effect, I've also adjusted for weekend and month to attempt to account for temporal trends. I've also included a population offset.

```{r linear_poisson_mod}
# limit to total group
strata_sub_ed <- ed_ts %>% 
  filter(strata == "total") 

# vector of names of outcomes to regress
outcomes <- colnames(ed_ts)[4:14]
# feed vector in to purrr map_dfr and run mixed model on each outcome
results <- outcomes %>% 
  map_dfr(function(x) {
    mod <- glmer(as.formula(paste0(x, 
        "~gwr_smk10+weekend+month+(1|fips)+offset(log(population))")),
        family = "poisson"(link="log"), 
        data = strata_sub_ed, 
        control = glmerControl(optimizer = "bobyqa"))
    
    # broom:tidy the model
    result <- broom::tidy(mod) %>% 
      filter(term == "gwr_smk10") %>% 
      mutate(rr = round(exp(estimate),3),
             lower95 = round(exp(estimate-(1.96*std.error)),3),
             upper95 = round(exp(estimate+(1.96*std.error)),3),
             p = round(p.value,3)) %>% 
      select(rr:p)
    
    outcome <- as_data_frame(as.character(x)) %>% rename(outcome = value)
    output_result <- bind_cols(outcome, result)
    return(output_result)
  }
) # end map function
```

Finished running mixed Poisson models. Printing output as a table.

```{r poisson_table}
knitr::kable(results, caption = paste0("Association between 10 ug/m^3",
  " increase in smoke PM2.5 and cardiopulmonary outcomes"))
```

Plotting results in the table.

```{r poisson_plot}
# preserve factor level and add group variable
results_plot <- results %>% 
  mutate(outcome = forcats::fct_relevel(outcome,
    results$outcome),
    group = as.factor(if_else(outcome %in% outcomes[1:5], 
                    "respiratory", "cardiovascular")))

ggplot(data=results_plot, aes(x=outcome, y = rr, colour = group)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), width = 0.3) +
  scale_color_manual(values = c("#9cecfb", "#ff00cc")) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "red") +
  ylab("Risk Ratio") +
  xlab("Outcome") +
  ggtitle(paste0("Association between smoke and ED admissions")) +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 90, hjust=0.95, vjust = 0.75))
```

Looks like these time series models show no or very weak associations (except maybe COPD). 

### Sensitivity Analyses

Performing some sensitivity tests. When I looked at the emergency room time series, I saw some sharp declines in the counts at the end of September. This could be due to health care systems switching over to ICD-10 before the HHS dead line of October 1, 2015, and therefore the counts based on ICD-9 may not be accurate. This could also be an argument for a case-crossover approach.

I'll try by looking at trends on in August 2015.

```{r august_ts}
# limit to total group
strata_sub_ed <- ed_ts %>% 
  filter(strata == "total") %>% 
  filter(month == 08)

# vector of names of outcomes to regress
outcomes <- colnames(ed_ts)[4:14]
# feed vector in to purrr map_dfr and run mixed model on each outcome
results <- outcomes %>% 
  map_dfr(function(x) {
    mod <- glmer(as.formula(paste0(x, 
        "~gwr_smk10+weekend+(1|fips)+offset(log(population))")),
        family = "poisson"(link="log"), 
        data = strata_sub_ed, 
        control = glmerControl(optimizer = "bobyqa"))
    
    # broom:tidy the model
    result <- broom::tidy(mod) %>% 
      filter(term == "gwr_smk10") %>% 
      mutate(rr = round(exp(estimate),3),
             lower95 = round(exp(estimate-(1.96*std.error)),3),
             upper95 = round(exp(estimate+(1.96*std.error)),3),
             p = round(p.value,3)) %>% 
      select(rr:p)
    
    outcome <- as_data_frame(as.character(x)) %>% rename(outcome = value)
    output_result <- bind_cols(outcome, result)
    return(output_result)
  }
) # end map function and add some variables

results_plot <- results %>% 
  mutate(outcome = forcats::fct_relevel(outcome,
    results$outcome),
    group = as.factor(if_else(outcome %in% outcomes[1:5], 
                    "respiratory", "cardiovascular")))

ggplot(data=results_plot, aes(x=outcome, y = rr, colour = group)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), width = 0.3) +
  scale_color_manual(values = c("#9cecfb", "#ff00cc")) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "red") +
  ylab("Risk Ratio") +
  xlab("Outcome") +
  ggtitle(paste0("Sensitivty: August Only")) +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 90, hjust=0.95, vjust = 0.75))
```

These results are slightly different; signals are slightly stronger and I see a signal with CVD. Although that just says to me that I have some sort of temporal bias or confounding. Maybe makes the argument for trying to fit a spline to PM~2.5~ series.

I'll also check if there may be evidence of some sort of spatial variable by checking results for Spokane county only. I think was impacted by smoke during this time and we can be relatively confident in the exposure estimate.

```{r spokane_ts}
# limit to total group
strata_sub_ed <- ed_ts %>% 
  filter(strata == "total") %>% 
  filter(fips == "53063")

# vector of names of outcomes to regress
outcomes <- colnames(ed_ts)[4:14]
# feed vector in to purrr map_dfr and run mixed model on each outcome
results <- outcomes %>% 
  map_dfr(function(x) {
    mod <- glm(as.formula(paste0(x, 
        "~gwr_smk10+weekend+month+offset(log(population))")),
        family = "poisson"(link="log"), 
        data = strata_sub_ed)
    
    # broom:tidy the model
    result <- broom::tidy(mod) %>% 
      filter(term == "gwr_smk10") %>% 
      mutate(rr = round(exp(estimate),3),
             lower95 = round(exp(estimate-(1.96*std.error)),3),
             upper95 = round(exp(estimate+(1.96*std.error)),3),
             p = round(p.value,3)) %>% 
      select(rr:p)
    
    outcome <- as_data_frame(as.character(x)) %>% rename(outcome = value)
    output_result <- bind_cols(outcome, result)
    return(output_result)
  }
) # end map function and add some variables

results_plot <- results %>% 
  mutate(outcome = forcats::fct_relevel(outcome,
    results$outcome),
    group = as.factor(if_else(outcome %in% outcomes[1:5], 
                    "respiratory", "cardiovascular"))) %>% 
  filter(outcome != "acute_bronch")

ggplot(data=results_plot, aes(x=outcome, y = rr, colour = group)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), width = 0.3) +
  scale_color_manual(values = c("#9cecfb", "#ff00cc")) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "red") +
  ylab("Risk Ratio") +
  xlab("Outcome") +
  ggtitle(paste0("Sensitivty: Spokane")) +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 90, hjust=0.95, vjust = 0.75))
```

There may be some temporal variability as well, but this should be a county that the exposure should be pretty accurate. I think that it may be possible that the signals do reflect that persons in this smokey county may have stayed in doors or took other mitigation strategies. 

Anyways, I think the mixed model with all counties is fine and accounts for this possible temporal variability. It's very possible I need to assess the distributed lag relationship and include a spline or some sort of period function that predicts the exposure series not impacted by smoke. 

## Accounting for Background Exposure

Peng et al. advocates for fitting a spline to the exposure series, and not the outcome series. I found an abstract that found fitting a spline to the outcome series works, but can lead to underestimation of the effect size. Also, fitting a spline to the exposure means I need to fit only one spline rather than many to each exposure.

Insert Peng article reference here.

Prepping data by limiting to total strata and removing any fips missing PM~2.5~ estimates.

```{r spline_data_prep}
# limit to total group
total_ed <- ed_ts %>% 
  filter(strata == "total") %>% 
  filter(!is.na(gwr))
```

For this analysis, I'm using the "splines" package to try and fit the general exposure series. I'll have to read over picking degrees of freedom again, but I've tried a couple different degrees of freedom with a natural spline and plotted these predicted values against observed and I think I remember some literature that said anywhere from 7 to 9 might fit pretty well for a year. However, I don't have a full year of PM~2.5~ data. And our data contains estimates due to smoke events, so it's not like a "normal" variation that might be expected in metro areas.  

I've run degrees of freedom from 5 to 13 and plotted small multiples to visualize fit. 

```{r spline_fit}
# define degrees of freedom
spl_df <- 5:20

# fit spline by date
spline_fits <- spl_df %>% 
  map_dfr(function(df_val){
    date <- total_ed$date
    # run spline based on date sequence
    spl <- ns(date, df = df_val)
    # model gwr_smoke units regressed on the spline
    pm_mod <- lm(gwr_smk10 ~ spl, data = total_ed)
    # estimated predicted values based on the spline and bind with dates
    pm_pred <- predict(pm_mod, type="response")
    # rep df val by length of prediction
    degree_freedom <- rep(df_val, length(pm_pred))
    # rep aic val by lenth of prediction 
    aic <- round(rep(AIC(pm_mod), length(pm_pred)),2)
    # join with total_ed 
    plot_df <- total_ed %>% 
      select(date, fips, gwr_smk10) %>% 
      cbind(pm_pred, degree_freedom, aic)
  } # end function
) # end map 
```

Table of AIC values degrees of freedom.
```{r pm_aic_tab}
pm_aic_tab <- spline_fits %>% 
  group_by(degree_freedom) %>% 
  summarise(aic = min(aic))

pm_aic_tab
```


Plotting fits of splines to see how well spline estimates track PM~2.5~ exposure series.

```{r spline_fit_plot}
head(spline_fits)
ggplot(data = spline_fits, aes(x=date, y=gwr_smk10)) +
  geom_point(colour = "#24c6dc", size = 0.2) +
  geom_line(aes(x=date, y=pm_pred), colour = "#ff00cc") +
  facet_wrap(~degree_freedom) +
  ggtitle("Spline fit of PM2.5 by degrees of freedom") +
  xlab("2015") +
  ylab("GWR Smoke PM2.5 ug/m^3") +
  ryan_theme
```

With less degrees of freedom, the spline fit is less pronounced. Even at the higher degrees of freedom, the major smoke event doesn't have much of an influence, but you can see the line influenced slightly. Peng et al. 2006 suggests that there is less bias overall with ns splines with higher degrees of freedom, but I also don't want to slow down my mixed effects model too much since the more knots there are, the longer it will take to run. I wonder if that's appropriate? Question to think about.

Fitting univariate model with 13 degrees of freedom spline. Has a relatively low AIC and I think my models should converge.

```{r results_pm_spline}
# define pm spline
pm_spl <- ns(total_ed$date, df = 13)

# vector of names of outcomes to regress
outcomes <- colnames(total_ed)[4:14]
# feed vector in to purrr map_dfr and run mixed model on each outcome
results <- outcomes %>% 
  map_dfr(function(x) {
    mod <- glmer(as.formula(paste0(x, 
        "~gwr_smk10+pm_spl+(1|fips)+offset(log(population))")),
        family = "poisson"(link="log"), 
        data = total_ed, 
        control = glmerControl(optimizer = "bobyqa"))
    # broom:tidy the model
    result <- broom::tidy(mod) %>% 
      filter(term == "gwr_smk10") %>% 
      mutate(rr = round(exp(estimate),3),
             lower95 = round(exp(estimate-(1.96*std.error)),3),
             upper95 = round(exp(estimate+(1.96*std.error)),3),
             p = round(p.value,3)) %>% 
      select(rr:p)
    
    outcome <- as_data_frame(as.character(x)) %>% rename(outcome = value)
    output_result <- bind_cols(outcome, result)
    return(output_result)
  }
) # end map function
```

Plot of GWR smoke association with cardiopulmonary outcomes with a spline fit to PM~2.5~.

```{r spline_plot}
results_plot <- results %>% 
  mutate(outcome = forcats::fct_relevel(outcome,
    results$outcome),
    group = as.factor(if_else(outcome %in% outcomes[1:6], 
                    "respiratory", "cardiovascular"))) 

ggplot(data=results_plot, aes(x=outcome, y = rr, colour = group)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), width = 0.3) +
  scale_color_manual(values = c("#9cecfb", "#ff00cc")) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "red") +
  ylab("Risk Ratio") +
  xlab("Outcome") +
  ggtitle(paste0("Association with spline")) +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 90, hjust=0.95, vjust = 0.75))
```

The spline doesn't really change findings too much. I also played around with different spline degrees of freedom and that can change the results somewhat, but not noticeably so. I could also try periodic type functions like sine/cosine functions.

# Distributed Lag 

I'm going to try and fit a distributed lag model to estimate lagged associations and also cumulative associations over 5 days. I thought about a week, but that would cut off a half month of data.

```{r lag_values}
# general code to create lagged variables
# may be worth creating in a function one day
gwr_lag <- pm %>% 
  select(fips, date, gwr_smk) %>% 
  arrange(fips, date) %>% 
  group_by(fips) %>% 
  mutate(gwr_smk10 = gwr_smk/10,
         gwr_smk_lag1 = lag(gwr_smk10, 1, order_by = fips),
         gwr_smk_lag2 = lag(gwr_smk10, 2, order_by = fips),
         gwr_smk_lag3 = lag(gwr_smk10, 3, order_by = fips),
         gwr_smk_lag4 = lag(gwr_smk10, 4, order_by = fips),         
         gwr_smk_lag5 = lag(gwr_smk10, 5, order_by = fips),
         gwr_smk_lag6 = lag(gwr_smk10, 6, order_by = fips)) %>% 
  select(-gwr_smk)

# join with morbidity data
ed_ts_lag <- total_ed %>%
  select(-gwr_smk10) %>% 
  left_join(gwr_lag, by = c("fips", "date")) %>% 
  filter(complete.cases(.)) 
```

Create PM~2.5~ matrix based on the lag exposure, and apply a natural spline "ns" over the 7 days. I've assigned degrees of freedom as 4. I generally find 3 to 5 works fine, and the shape doesn't really change. 

```{r smoke_matrix}
# output matrix of smoke and lag variables
smk_matrix <- as.matrix(select(ed_ts_lag, gwr_smk10:gwr_smk_lag6))
```

Finding best-fit of lag spline for degrees of freedom 3 to 5.
```{r dl_fit_function}
#function
dl_fit <- function(data, exp_mat, outcome, 
                   lag_df, pm_spline) {
        # create list of lengh pm_df
        mod_aic <- sapply(lag_df, function(x){
          pm_b <- splines::ns(0:(ncol(exp_mat)-1), df=x, intercept=T)
          # create pm basis
          pm_basis <- exp_mat %*% pm_b
          # run model
          mod <- glmer(as.formula(paste0(outcome, 
            "~pm_basis + pm_spline + (1|fips) + offset(log(population))")),
             data, family="poisson"(link="log"), 
             control = glmerControl(optimizer = "bobyqa"))
          aic <- AIC(mod)
        return(aic)
      }) # end sapply
    # create aic df
    pm_df_aic <- data.frame(outcome, lag_df, mod_aic)
    return(pm_df_aic)
}
```

Using the fit function to find the model with the best fit based on the lowest AIC. 

```{r dl_lag_fit}
# defining exposure spline with 13 df
pm_spl <- ns(ed_ts_lag$date, df = 13)
# find aic fit for each outcome
dl_fit_df <- outcomes %>% 
  map_dfr(~dl_fit(data=ed_ts_lag, exp_mat = smk_matrix, outcome = .,
                  lag_df = 2:5, pm_spline = pm_spl)) %>% 
  mutate(outcome = forcats::fct_relevel(outcome, outcomes))

# output degrees of freedom minimum aic 
min_aic <- dl_fit_df %>% 
  group_by(outcome) %>% 
  slice(which.min(mod_aic))

# print table
knitr::kable(min_aic, caption = "Best-fit spline for distributed lag")
```


Creating distributed lag function that outputs a dataframe of lagged values and cumulative effect over the lag period.

Note on function: consider adding a covariate option instead of pm_spline. I could then add covariates like weekend, with relative ease rather than updating the formula inside of function itself.

```{r dl_function}
# distributed lag function
distributed_lag <- function(data, exp_mat, outcome, 
                            lag_df, pm_spline){
  # define basis b using natural spline function
  pm_b <- ns(0:(ncol(exp_mat)-1), df = lag_df, intercept = T)
  # multiply lagged pm matrix by basis
  pm_basis <- exp_mat %*% pm_b
  # fit mixed model
  mod <- glmer(as.formula(paste0(outcome, 
            "~pm_basis + pm_spline + (1|fips) + offset(log(population))")),
             data, family="poisson"(link="log"), 
             control = glmerControl(optimizer = "bobyqa"))
  
  # calculate estimates ----
  # output pm basis parameters
  dl_parms <- broom::tidy(mod) %>% 
    filter(stringr::str_detect(term, "pm_basis")) %>% 
    select(estimate) %>% 
    as_vector()
  
  # estimate distributed lag values for each day
  estimate <-  pm_b %*% dl_parms
  # time variable
  time <- ((rep(1:length(estimate))-1))
  # covariance matrix for knots 
  # fix the matrix
  cov_matrix <- as.matrix(vcov(mod))[2:(lag_df+1), 2:(lag_df+1)]
  # estimate variance of spline
  variance <- pm_b %*% cov_matrix %*% t(pm_b)
  # estimate lag ----
  # estimate standard error for each lag day
  l_se <- sqrt(diag(variance))
  # calculate lower and upper bound
  l_lower95 <- estimate+(l_se*qnorm(1-0.975))
  l_upper95 <- estimate+(l_se*qnorm(0.975))
  l_type <- as.character(rep("lag", times = length(estimate)))
  # l_estimate
  l_estimate <- data.frame(outcome, l_type, time, exp(estimate), 
                                  exp(l_lower95), exp(l_upper95)) 
  # assign column names
  colnames(l_estimate) <- c("outcome", "type","time", "estimate",
                            "lower95","upper95") 

  # estimate cumulative ----
  c_type <- as.character(rep("cumulative", times = length(estimate)))
    # sequential cumulative estimate
    cumulative_estimate <- sapply(seq_along(estimate), function(x){
        sum(estimate[1:x])
      })
    # stderr cumulative effect
    cumulative_se <- sapply(seq_along(estimate), function(x){
        sqrt(sum(variance[1:x,1:x]))
      })
  # cumulative 95CI
  c_lower95 <- cumulative_estimate+(cumulative_se*qnorm(1-0.975))
  c_upper95 <- cumulative_estimate+(cumulative_se*qnorm(0.975))
  # return dataframe
  c_estimate <- data.frame(outcome, c_type, time,
    exp(cumulative_estimate), exp(c_lower95), exp(c_upper95))
  # assign column names
  colnames(c_estimate) <- c("outcome", "type","time","estimate",
                                 "lower95","upper95") 
  
  # bind lag and cumulative estimates together
  return_estimate <- rbind(c_estimate, l_estimate)
  # return estimate  
  return(return_estimate)
} # end of function
```

Estimating the cumulative effect of GWR smoke on cardiopulmonary outcomes with a the fit degree of freedom spline for lagged response and a 7 degree of freedom PM~2.5~ exposure spline. Accounting for county as a random intercept.

Running distributed_lag function on vector of each outcome.

```{r dl_results}
# defining exposure spline
pm_spl <- ns(ed_ts_lag$date, df = 13)
# create outcome vector and degrees of freedom vector to use map2 function
outcome_vector <- min_aic$outcome
df_vector <- min_aic$lag_df
# estimate cumulative results
dl_results <- map2(.x=outcome_vector, .y=df_vector,
  ~distributed_lag(data=ed_ts_lag, exp_mat = smk_matrix, outcome = .x, 
                   lag_df = .y, pm_spline = pm_spl)) %>% 
  plyr::rbind.fill()

#knitr::kable(dl_results, caption = "Distributed lag results")
```

## Cumulative Effect

Plotting cumulative results.

```{r cumulative_plot}
cumulative_results <- dl_results %>% 
  filter(type == "cumulative")
# plot
ggplot(cumulative_results, aes(x=time, y=estimate)) +
  geom_line(colour = "#0ed2f7", size = 1) +
  geom_ribbon(aes(ymin = lower95, ymax = upper95), 
              fill = "#b2fefa", alpha = 0.3) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  facet_wrap(~outcome) +
  ylab(expression("RR: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Lagged Days") +
  ggtitle("Cumulative") +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank())
```

It looks like over five to six days of cumulative exposure to smoke PM~2.5~ increases the risk for respiratory emergency department hospitalizations. This appears to be the case for asthma and COPD around 4 days. For cardiovascular outcomes, there may be an increase in the rate after multiple days of exposure. This might hold true for the CVD outcomes of arrhythmia, and myocardial infarction (a sub-classification of ischemic heart disease and likely the majority of events, which is probably why the signal is similar).

## Lagged Effect

Plotting lagged effect of specific days.

```{r lagged_results}
# estimate lagged results
lagged_results <- dl_results %>% 
  filter(type == "lag")
# plot
ggplot(lagged_results, aes(x=time, y=estimate)) +
  geom_line(colour = "#673ab7", size = 1) +
  geom_ribbon(aes(ymin = lower95, ymax = upper95), 
              fill = "#9d50bb", alpha = 0.3) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  facet_wrap(~outcome) +
  ylab(expression("RR: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Lagged Days") +
  ggtitle("Lagged") +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank())
```

Lagged days give some interesting shapes for asthma and COPD that may suggest harvesting, where there is a peak, then a dip in the rates. Shape may be a little wonky with degrees of freedom of 4+. Could be real though.

## Sensitivity Analysis

I'm concerned about the last week or so of September where the counts drop off. This is a similar thing I've seen at the end of each year which I sometimes attributed to the New Years, but it could also be that those admissions are processed in early January the following year and possibly counted. In the case of the switch from ICD-9 to ICD-10, it could be that persons admitted on the last couple days of September 2015 that would normally be coded using ICD-9 could have been coded using ICD-10. I'm going to run the distributed lag analyses excluding the last week of September 2015.

Starting filtering the dataframe to exclude the last week of September.
```{r dl_sen_subset}
# subset dataframe
ed_lag_sn <- ed_ts_lag %>% 
  filter(date <= "2015-09-24")

# subset smoke matrix
smk_mat_sn <- as.matrix(select(ed_lag_sn, gwr_smk10:gwr_smk_lag6))
```

Finding new distributed lag spline fits.

```{r lag_fit_sn}
# redfine pm_spl based on new date vector
pm_spl_sn <-ns(ed_lag_sn$date, df = 13)
# find aic fit for each outcome
dl_fit_df_sn <- outcomes %>% 
  map_dfr(~dl_fit(data=ed_lag_sn, exp_mat = smk_mat_sn, outcome = .,
                  lag_df = 2:5, pm_spline = pm_spl_sn)) %>% 
  mutate(outcome = forcats::fct_relevel(outcome, outcomes))

# output degrees of freedom minimum aic 
min_aic_sn <- dl_fit_df %>% 
  group_by(outcome) %>% 
  slice(which.min(mod_aic))

# print table
knitr::kable(min_aic_sn, caption = paste0("Sensitivity: best-fit spline for",
                                       " distributed lag"))
```

Running sensitivit results based on new degrees of freedom.

```{r dl_sn_results}
# defining exposure spline
pm_spl_sn <-ns(ed_lag_sn$date, df = 13)
# create outcome vector and degrees of freedom vector to use map2 function
outcome_vector <- min_aic_sn$outcome
df_vector <- min_aic_sn$lag_df
# estimate cumulative results
dl_sn_results <- map2(.x=outcome_vector, .y=df_vector,
  ~distributed_lag(data=ed_lag_sn, exp_mat = smk_mat_sn, 
                          outcome = .x, lag_df = .y, 
                   pm_spline = pm_spl_sn)) %>% 
  plyr::rbind.fill()
```

Sensitivity cumulative effect results.

```{r cumulative_sn_plot}
cumulative_results <- dl_sn_results %>% 
  filter(type == "cumulative")
# plot
ggplot(cumulative_results, aes(x=time, y=estimate)) +
  geom_line(colour = "#0ed2f7", size = 1) +
  geom_ribbon(aes(ymin = lower95, ymax = upper95), 
              fill = "#b2fefa", alpha = 0.3) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  facet_wrap(~outcome) +
  ylab(expression("RR: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Lagged Days") +
  ggtitle("Sensitivity: Cumulative") +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank())
```

Sensitivity lagged results.

```{r lagged_sn_results}
# estimate lagged results
lagged_results <- dl_sn_results %>% 
  filter(type == "lag")
# plot
ggplot(lagged_results, aes(x=time, y=estimate)) +
  geom_line(colour = "#673ab7", size = 1) +
  geom_ribbon(aes(ymin = lower95, ymax = upper95), 
              fill = "#9d50bb", alpha = 0.3) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  facet_wrap(~outcome) +
  ylab(expression("RR: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Lagged Days") +
  ggtitle("Sensitivity: Lagged") +
  ryan_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank())
```





